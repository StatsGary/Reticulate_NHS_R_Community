library(vip)         # for variable importance plots
library(tidymodels)
library(readr)
hotels <-
read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%
mutate_if(is.character, as.factor)
dim(hotels)
glimpse(hotels)
hotels %>%
count(children) %>%
mutate(prop = n/sum(n))
library(tidymodels)
# Helper packages
library(readr)       # for importing data
library(vip)         # for variable importance plots
library(tidymodels)
library(readr)
hotels <-
read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%
mutate_if(is.character, as.factor)
dim(hotels)
glimpse(hotels)
hotels %>%
count(children) %>%
mutate(prop = n/sum(n))
set.seed(123)
splits      <- initial_split(hotels, strata = children)
hotel_other <- training(splits)
hotel_test  <- testing(splits)
hotel_other %>%
count(children) %>%
mutate(prop = n/sum(n))
hotel_test  %>%
count(children) %>%
mutate(prop = n/sum(n))
set.seed(234)
val_set <- validation_split(hotel_other,
strata = children,
prop = 0.80)
val_set
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter",
"ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")
lr_recipe <-
recipe(children ~ ., data = hotel_other) %>%
step_date(arrival_date) %>%
step_holiday(arrival_date, holidays = holidays) %>%
step_rm(arrival_date) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
lr_workflow <-
workflow() %>%
add_model(lr_mod) %>%
add_recipe(lr_recipe)
###################Exercise 5 - Predictive Modelling Case Study####################
#https://www.tidymodels.org/start/case-study/
library(tidymodels)
# Helper packages
library(readr)       # for importing data
library(vip)         # for variable importance plots
library(tidymodels)
library(readr)
hotels <-
read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%
mutate_if(is.character, as.factor)
dim(hotels)
glimpse(hotels)
hotels %>%
count(children) %>%
mutate(prop = n/sum(n))
set.seed(123)
splits      <- initial_split(hotels, strata = children)
hotel_other <- training(splits)
hotel_test  <- testing(splits)
hotel_other %>%
count(children) %>%
mutate(prop = n/sum(n))
hotel_test  %>%
count(children) %>%
mutate(prop = n/sum(n))
# Do a validation and training split
set.seed(234)
val_set <- validation_split(hotel_other,
strata = children,
prop = 0.80)
val_set
lr_mod <-
logistic_reg(penalty = tune(), mixture = 1) %>%
set_engine("glmnet")
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter",
"ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")
lr_recipe <-
recipe(children ~ ., data = hotel_other) %>%
step_date(arrival_date) %>%
step_holiday(arrival_date, holidays = holidays) %>%
step_rm(arrival_date) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
lr_workflow <-
workflow() %>%
add_model(lr_mod) %>%
add_recipe(lr_recipe)
print(lr_workflow)
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
lr_reg_grid %>% top_n(-5) # lowest penalty values
lr_res <-
lr_workflow %>%
tune_grid(val_set,
grid = lr_reg_grid,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
install.packages("glmnet")
lr_res <-
lr_workflow %>%
tune_grid(val_set,
grid = lr_reg_grid,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
lr_plot <-
lr_res %>%
collect_metrics() %>%
ggplot(aes(x = penalty, y = mean)) +
geom_point() +
geom_line() +
ylab("Area under the ROC Curve") +
scale_x_log10(labels = scales::label_number())
lr_plot
top_models <-
lr_res %>%
show_best("roc_auc", n = 15) %>%
arrange(penalty)
top_models
top_models <-
lr_res %>%
show_best("roc_auc", n = 15) %>%
arrange(penalty)
top_models
lr_best <-
lr_res %>%
collect_metrics() %>%
arrange(penalty) %>%
slice(12)
lr_best
lr_best <-
lr_res %>%
collect_metrics() %>%
arrange(penalty) %>%
slice(12)
lr_best
lr_auc <-
lr_res %>%
collect_predictions(parameters = lr_best) %>%
roc_curve(children, .pred_children) %>%
mutate(model = "Logistic Regression")
autoplot(lr_auc)
cores
cores <- parallel::detectCores()
cores
rf_mod <-
rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
cores <- parallel::detectCores()
cores
# Fit model
rf_mod <-
rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
rf_recipe <-
recipe(children ~ ., data = hotel_other) %>%
step_date(arrival_date) %>%
step_holiday(arrival_date) %>%
step_rm(arrival_date)
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(rf_recipe)
# Create workflow
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(rf_recipe)
# Train and tune the model
rf_mod
rf_mod %>%
parameters()
#Tune grid via grid tuning
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(val_set,
grid = 25,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
#Tune grid via grid tuning
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(val_set,
grid = 25,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
#Tune grid via grid tuning
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(val_set,
grid = 25,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
rf_res %>%
show_best(metric = "roc_auc")
autoplot(rf_res)
rf_best
rf_best <-
rf_res %>%
select_best(metric = "roc_auc")
rf_best
autoplot(rf_res)
rf_best <-
rf_res %>%
select_best(metric = "roc_auc")
rf_best
rf_res %>%
collect_predictions()
rf_auc <-
rf_res %>%
collect_predictions(parameters = rf_best) %>%
roc_curve(children, .pred_children) %>%
mutate(model = "Random Forest")
bind_rows(rf_auc, lr_auc) %>%
ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) +
geom_path(lwd = 1.5, alpha = 0.8) +
geom_abline(lty = 3) +
coord_equal() +
scale_color_viridis_d(option = "plasma", end = .6)
# the last model
last_rf_mod <-
rand_forest(mtry = 8, min_n = 7, trees = 1000) %>%
set_engine("ranger", num.threads = cores, importance = "impurity") %>%
set_mode("classification")
# the last workflow
last_rf_workflow <-
rf_workflow %>%
update_model(last_rf_mod)
# the last fit
set.seed(345)
last_rf_fit <-
last_rf_workflow %>%
last_fit(splits)
last_rf_fit
last_rf_fit %>%
pluck(".workflow", 1) %>%
pull_workflow_fit() %>%
vip(num_features = 20)
last_rf_fit %>%
collect_predictions() %>%
roc_curve(children, .pred_children) %>%
autoplot()
library(NHSRdatasets)
NHSRdatasets::ae_attendances
NHSRdatasets::LOS_model
install.packages("devtools")
devtools::install_github("yihui/xaringan")
install.packages("xaringan")
install.packages("distill")
iris <- iris
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
.connection_string = 'driver={SQL Server};Server=localhost\SQLEXPRESS;Database=RDatabase;Trusted_Connection=True;')
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
.connection_string = 'driver=SQL Server;Server=localhost\SQLEXPRESS;Database=RDatabase;Trusted_Connection=True;')
con <- dbConnect(odbc::odbc(),
.connection_string = "driver=SQL Server;Server=localhost\SQLEXPRESS;Database=RDatabase;Trusted_Connection=True;")
con <- dbConnect(odbc::odbc(),
.connection_string = "Server=localhost\SQLEXPRESS;Database=RDatabase;Trusted_Connection=True;")
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 13 for SQL Server",
Server = "localhost",
Database = "RDatabase",
Trusted_Connection = "yes"
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 13 for SQL Server",
Server = "localhost",
Database = "RDatabase",
Trusted_Connection = "yes")
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 13 for SQL Server",
Server = "localhost",
Database = "RDatabase",
Trusted_Connection = "yes")
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 13 for SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "master",
Trusted_Connection = "yes")
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 13 for SQL Server",
Server = "localhost",
Database = "master",
Trusted_Connection = "yes")
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 13 for SQL Server",
Server = "localhost",
Database = "master",
Trusted_Connection = T)
odbc::odbcListDrivers()
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 17 for SQL Server",
Server = "localhost",
Database = "master",
Trusted_Connection = T)
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "ODBC Driver 17 for SQL Server",
Server = "localhost\\SQLEXPESS",
Database = "master",
Trusted_Connection = "True")
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPESS",
Database = "master",
Trusted_Connection = "True")
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPESS",
Database = "RDatabase",
Trusted_Connection = "True")
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPESS",
Database = "RDatabase",
Trusted_Connection = "True")
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPESS",
Database = "master",
Trusted_Connection = "True")
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "LAPTOP-GE3S96EI\SQLEXPRESS",
Database = "master",
Trusted_Connection = "True")
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "localhost\SQLEXPESS",
Database = "master",
Trusted_Connection = "True")
con <- dbConnect(odbc::odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPESS",
Database = "master",
Trusted_Connection = "True")
iris <- iris
# Write IRIS to database
library(odbc)
library(DBI)
con <- dbConnect(odbc::odbc(),
Driver = "{SQL Server}",
Server = "localhost\\SQLEXPESS",
Database = "master",
Trusted_Connection = "True")
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
iris <- iris
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
con <- dbConnect(odbc(),
Driver = "ODBC Driver 17 for SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "datawarehouse",
Trusted_Connection = "True")
iris <- iris
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
con <- dbConnect(odbc(),
Driver = "ODBC Driver 17 for SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "master",
Trusted_Connection = "True")
con <- dbConnect(odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "master",
Trusted_Connection = "True")
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
con <- dbConnect(odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "master",
Trusted_Connection = "True")
schema_name <- "data"
# Use odbc to write data
cm_table <- "iris"
iris <- iris
odbc::dbWriteTable(con, Id(schema = "Log", table = cm_table), iris, append = FALSE, overwrite = TRUE)
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
con <- dbConnect(odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "RDatabase",
Trusted_Connection = "True")
schema_name <- "data"
# Use odbc to write data
cm_table <- "iris"
iris <- iris
odbc::dbWriteTable(con, Id(schema = "data", table = cm_table), iris, append = FALSE, overwrite = TRUE)
library(odbc)
library(DBI)
library(NHSRdatasets)
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
con <- dbConnect(odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "RDatabase",
Trusted_Connection = "True")
schema_name <- "data"
# Use odbc to write data
cm_table <- "iris"
iris <- iris
odbc::dbWriteTable(con, Id(schema = "data", table = cm_table), iris, append = FALSE, overwrite = TRUE)
# Copy NHS R Datasets
library(odbc)
library(DBI)
library(NHSRdatasets)
# Write IRIS to database
sort(unique(odbcListDrivers()[[1]]))
con <- dbConnect(odbc(),
Driver = "SQL Server",
Server = "localhost\\SQLEXPRESS",
Database = "RDatabase",
Trusted_Connection = "True")
schema_name <- "data"
# Use odbc to write data
cm_table <- "iris"
iris <- iris
odbc::dbWriteTable(con, Id(schema = "data", table = cm_table), iris, append = FALSE, overwrite = TRUE)
# Copy NHS R Datasets
cm_table <- "ae_attendances"
ae <- NHSRdatasets::ae_attendances
odbc::dbWriteTable(con, Id(schema = "data", table = cm_table), ae, append = FALSE, overwrite = TRUE)
source('C:/Users/garyh/Desktop/RConnectToLocalHost.R')
setwd("~/GitHub/Reticulate_NHS_R_Community")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(tidyverse)
library(caret)
library(tidymodels)
library(magrittr)
library(plotly)
library(data.table)
#Create python objects as R
numpy <- import("numpy")
pandas <- import("pandas")
# Import libraries for ski-kit learn
sl_model_selection <- import("sklearn.model_selection")
skl <- import("sklearn")
skl_ensemble <- import("sklearn.ensemble")
skl_pipeline <- import("sklearn.pipeline")
skl_metrics <- import("sklearn.metrics")
skl_externals <- import("sklearn.externals")
skl_lm <- import("sklearn.linear_model")
# Import visualisation libraries
sns <- import('seaborn')
plt <- import('matplotlib.pyplot')
ttbs <- read_csv("Data/TTBS_Prediction.csv")
ttbs %<>%
sample_frac(size=0.2)
View(ttbs)
